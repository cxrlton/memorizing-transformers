{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "!pip install einops\n",
        "from einops import rearrange, repeat, pack, unpack, einsum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMxjrY28ioq-",
        "outputId": "50350436-0321-4be8-a64c-7e804bfb7fc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1st segment: compute current kv projections [kv_1] and perform attention\n",
        "# 2nd segment: concatenate old kv projections with current kv projections [kv1 + kv2] and perform attention\n",
        "# 3rd segment: concatenate old kv projections with current kv projections [kv2 + kv3] and perform attention\n",
        "# 4th segment: concatenate old kv projections with current kv projections [kv3 + kv4] and perform attention\n",
        "# ...\n",
        "\n",
        "# 1st segment:\n",
        "seg_one_kv = [seg_1_layer_1_kv,\n",
        "            seg_1_layer_2_kv,\n",
        "            seg_1_layer_3_kv,\n",
        "              ...]\n",
        "\n",
        "# 2nd segment:\n",
        "seg_two_kv = [concatenate(seg_1_layer_1_kv, seg_2_layer_1_kv),\n",
        "            concatenate(seg_1_layer_2_kv, seg_2_layer_2_kv),\n",
        "            concatenate(seg_1_layer_3_kv, seg_2_layer_3_kv),\n",
        "                ...]\n",
        "\n",
        "# 3rd segment:\n",
        "seg_three_kv = [concatenate(seg_2_layer_1_kv, seg_3_layer_1_kv),\n",
        "            concatenate(seg_2_layer_2_kv, seg_3_layer_2_kv),\n",
        "            concatenate(seg_2_layer_3_kv, seg_3_layer_3_kv),\n",
        "                ...]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "5ie5fCcLiugq",
        "outputId": "29e219c4-ed53-414a-fb71-70f63e49326e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'seg_1_layer_1_kv' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-92471a8fe729>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# 1st segment:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m seg_one_kv = [seg_1_layer_1_kv,\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mseg_1_layer_2_kv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mseg_1_layer_3_kv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'seg_1_layer_1_kv' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "seq_len = 512\n",
        "head_dimension = 10\n",
        "number_heads = 8\n",
        "embedding_dimension = 13\n",
        "scaling_factor = 1"
      ],
      "metadata": {
        "id": "0-4MMYkRi0YT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create fake training batch\n",
        "input_data = torch.randn((batch_size, seq_len, embedding_dimension))\n",
        "input_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5is9Oyc4jA2u",
        "outputId": "a6a65527-2e85-4fcb-e7a0-b01cd43018a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 512, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize projection matrices\n",
        "query_matrix = nn.Linear(embedding_dimension, number_heads * head_dimension)\n",
        "key_matrix = nn.Linear(embedding_dimension, number_heads * head_dimension)\n",
        "value_matrix = nn.Linear(embedding_dimension, number_heads * head_dimension)\n",
        "output_matrix = nn.Linear(number_heads * head_dimension, embedding_dimension)"
      ],
      "metadata": {
        "id": "J2PxlIpYjB_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create KQV matrices with input data\n",
        "queries = query_matrix(input_data)\n",
        "keys = key_matrix(input_data)\n",
        "values = value_matrix(input_data)\n",
        "values.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_kkSS-ljEjE",
        "outputId": "e29fd8ce-2217-4c4b-c2d2-b892581d5411"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 512, 80])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a fake cached XL recurrence\n",
        "xl_memory = torch.randn(batch_size, seq_len,2,number_heads*head_dimension)\n",
        "xl_memory.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGQ3FHp3jGe7",
        "outputId": "a2470bbb-11d5-4347-ea6c-5306cf8eba75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 512, 2, 80])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xl_keys, xl_values = xl_memory.unbind(dim=-2)\n",
        "xl_keys.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wg7EP3F-jMd3",
        "outputId": "a7917fc9-7546-45a3-b85f-815994a3ab88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 512, 80])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys = torch.cat((xl_keys, keys), dim=-2)\n",
        "values = torch.cat((xl_values, values), dim=-2)\n",
        "values.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pytBBLxLjZq_",
        "outputId": "1ae0091e-38f5-49e2-d8ef-cd060fe66960"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 1024, 80])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "queries.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lVgy9BBjcsJ",
        "outputId": "f329f12f-b7b6-4162-e25e-6a677581d539"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 512, 80])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "queries = rearrange(queries, 'b t (h d) -> b h t d', h = number_heads)\n",
        "keys    = rearrange(keys, 'b t (h d) -> b h t d', h = number_heads)\n",
        "qk      = einsum(queries, keys, 'b h i d, b h j d -> b h i j')\n",
        "\n",
        "print (\"queries:\", queries.shape)\n",
        "print (\"keys:\", keys.shape)\n",
        "print (\"qk:\", qk.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQZsw7gnjhZi",
        "outputId": "7600e10f-8f3c-416c-8934-8a670da4f90f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "queries: torch.Size([16, 8, 512, 10])\n",
            "keys: torch.Size([16, 8, 1024, 10])\n",
            "qk: torch.Size([16, 8, 512, 1024])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Regular Self Attention QK (4,4)\n",
        "#\n",
        "# [    1., -1000., -1000., -1000.]\n",
        "# [    1.,     1., -1000., -1000.]\n",
        "# [    1.,     1.,     1., -1000.]\n",
        "# [    1.,     1.,     1.,     1.]\n",
        "\n",
        "\n",
        "\n",
        "# Transformer XL Self Attention QK (4,8)\n",
        "#\n",
        "# [    1.,     1.,     1.,     1.,     1., -1000., -1000., -1000.]\n",
        "# [    1.,     1.,     1.,     1.,     1.,     1., -1000., -1000.]\n",
        "# [    1.,     1.,     1.,     1.,     1.,     1.,     1., -1000.]\n",
        "# [    1.,     1.,     1.,     1.,     1.,     1.,     1.,     1.]"
      ],
      "metadata": {
        "id": "eqNeLe0yjnVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i, j = qk.shape[-2:]\n",
        "j"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1SCkoZEkE4Z",
        "outputId": "33d2ae61-58b9-477b-ea2a-9bb179bdeba8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1024"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create mask\n",
        "mask = torch.ones((i,j), dtype = torch.bool).triu(j-i+1)\n",
        "mask.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdUcN9YFkRL9",
        "outputId": "f53a6665-5fa7-4fbe-8e59-91d2047ef76c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([512, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qk = qk.masked_fill(mask, float('-inf'))"
      ],
      "metadata": {
        "id": "d_lPlFJQkiP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DhoOARKkntf",
        "outputId": "092bbe59-6531-4d72-9a78-e53941d7e188"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[-1.4778e+00, -2.4345e+00, -1.4185e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [-1.6760e+00,  1.4537e+00, -1.9621e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [-8.0605e-01, -3.6405e+00, -6.1674e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          ...,\n",
              "          [-2.1815e+00,  6.8134e-01, -2.3266e+00,  ...,  7.9539e-01,\n",
              "                  -inf,        -inf],\n",
              "          [-1.1277e+00, -1.0929e+00, -1.0921e-01,  ..., -2.3192e-01,\n",
              "           -1.1430e+00,        -inf],\n",
              "          [ 3.3872e+00,  1.5124e+00, -5.3877e-01,  ...,  2.1358e+00,\n",
              "            3.5113e+00, -1.3868e+00]],\n",
              "\n",
              "         [[ 5.4370e-01,  1.8310e+00, -1.4181e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 6.9232e-01, -2.7681e-01,  1.6967e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [-1.4152e+00, -3.1564e+00, -2.4268e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          ...,\n",
              "          [ 2.1014e+00,  3.5857e+00,  2.5429e+00,  ..., -7.8705e-01,\n",
              "                  -inf,        -inf],\n",
              "          [ 3.6688e+00,  2.6428e+00,  3.1329e+00,  ..., -1.2589e+00,\n",
              "           -1.1715e+00,        -inf],\n",
              "          [-5.3997e-01, -2.7680e-01, -1.9642e+00,  ...,  4.2234e-01,\n",
              "            5.8597e-01,  8.3251e-01]],\n",
              "\n",
              "         [[-2.8562e+00, -5.9122e-01,  2.2050e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [-1.6294e+00,  1.4517e+00,  4.2821e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 7.7282e-01,  8.1628e-01, -1.5179e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          ...,\n",
              "          [-2.1463e+00, -2.9804e-02,  2.5026e+00,  ...,  3.0902e-01,\n",
              "                  -inf,        -inf],\n",
              "          [-9.6182e-01,  8.3490e-01,  1.8592e+00,  ..., -2.7989e-01,\n",
              "           -1.1933e+00,        -inf],\n",
              "          [-9.4785e-01, -1.6699e+00, -1.7833e-01,  ...,  3.4353e-01,\n",
              "            6.6708e-01,  1.1699e+00]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[-2.3090e+00, -1.7469e-01, -1.5276e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [-2.0574e+00,  5.6835e-01,  1.8021e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [-2.7802e+00,  3.3497e+00, -1.2966e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          ...,\n",
              "          [ 6.1802e-02, -1.9870e+00,  1.5576e+00,  ...,  7.8565e-01,\n",
              "                  -inf,        -inf],\n",
              "          [-1.7279e+00, -1.3502e+00, -3.1589e+00,  ...,  1.5780e+00,\n",
              "            1.8671e+00,        -inf],\n",
              "          [-1.9721e+00,  1.3375e+00, -4.3561e+00,  ..., -2.6390e-03,\n",
              "           -8.9651e-01,  3.1886e-01]],\n",
              "\n",
              "         [[ 6.6676e-01,  1.8196e+00, -5.4544e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 3.3327e-01, -9.6293e-02,  9.7933e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 2.3317e-01,  2.6764e+00, -1.3852e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          ...,\n",
              "          [ 6.0225e-01, -9.0452e-01,  1.7603e+00,  ..., -3.3807e-01,\n",
              "                  -inf,        -inf],\n",
              "          [ 1.7666e+00,  8.5952e-01,  2.9805e+00,  ..., -5.3276e-01,\n",
              "            1.3148e-01,        -inf],\n",
              "          [-1.3525e+00, -1.6825e+00, -2.6214e-01,  ...,  4.6046e-01,\n",
              "            4.2364e-01, -1.0986e+00]],\n",
              "\n",
              "         [[ 1.1655e+00, -7.9764e-01, -4.3580e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 9.8891e-01, -6.9924e-01, -2.3385e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 3.0526e+00,  7.8633e-01,  1.0318e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          ...,\n",
              "          [ 7.2002e-03,  8.6680e-01, -1.4967e+00,  ..., -7.6884e-01,\n",
              "                  -inf,        -inf],\n",
              "          [ 1.1260e-01,  6.5777e-01, -2.1488e+00,  ..., -5.3331e-01,\n",
              "           -1.3698e+00,        -inf],\n",
              "          [-2.9198e+00, -1.5162e+00,  1.2498e+00,  ..., -1.6582e+00,\n",
              "           -1.3398e+00, -6.8976e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 6.1684e-01,  7.6545e-01,  7.7708e-02,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 1.5760e+00,  1.0791e-01,  3.9801e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 1.8083e+00,  9.9652e-01,  7.2518e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          ...,\n",
              "          [ 4.0703e+00, -1.0154e-01,  1.4665e-01,  ...,  9.2298e-01,\n",
              "                  -inf,        -inf],\n",
              "          [ 7.0903e-01, -5.8062e-02,  2.3187e+00,  ..., -1.0365e-01,\n",
              "           -9.6589e-01,        -inf],\n",
              "          [ 4.5792e+00,  3.2274e+00,  6.3414e-01,  ..., -8.6422e-01,\n",
              "            9.4122e-01,  3.6173e-01]],\n",
              "\n",
              "         [[-3.0577e+00, -3.9039e+00, -2.9854e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 4.1718e+00, -3.1345e-01, -1.8883e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [-2.7021e+00, -2.0556e+00, -6.1365e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          ...,\n",
              "          [ 2.2278e-01,  2.9132e+00,  7.5972e-01,  ...,  9.4570e-02,\n",
              "                  -inf,        -inf],\n",
              "          [-5.1129e-01, -3.2100e-01, -2.3580e+00,  ..., -2.4259e-02,\n",
              "            2.8509e-02,        -inf],\n",
              "          [-4.3262e+00,  1.7257e+00, -1.7165e+00,  ...,  1.2017e-01,\n",
              "           -9.3217e-01,  7.2892e-01]],\n",
              "\n",
              "         [[-1.9482e+00, -3.7426e+00, -1.6308e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [-5.6439e-01, -2.4703e+00,  1.3561e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [-1.8007e+00, -1.5645e+00, -1.4269e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          ...,\n",
              "          [ 2.0230e-01, -1.1690e+00,  3.8426e-02,  ..., -4.7341e-01,\n",
              "                  -inf,        -inf],\n",
              "          [-3.7973e-01, -1.8008e+00, -1.0603e+00,  ..., -4.7572e-01,\n",
              "            1.4871e+00,        -inf],\n",
              "          [ 2.2143e-01, -2.4238e-02, -1.0236e+00,  ...,  1.6711e-01,\n",
              "            5.0475e-01,  1.2311e+00]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 4.1453e+00, -1.5198e-01, -8.6665e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 3.0543e+00, -1.9830e+00,  9.9811e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 3.0891e+00,  7.8836e-01, -3.4914e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          ...,\n",
              "          [ 7.8440e-01,  1.1776e-01, -8.8137e-01,  ...,  2.7363e-01,\n",
              "                  -inf,        -inf],\n",
              "          [ 2.0963e+00,  4.4058e-01,  9.9902e-01,  ..., -4.7522e-01,\n",
              "           -3.1178e-01,        -inf],\n",
              "          [ 1.3057e+00,  1.4155e+00, -2.5348e+00,  ..., -4.0950e-01,\n",
              "           -6.3304e-02,  2.5646e-01]],\n",
              "\n",
              "         [[ 7.5411e-01,  5.4554e-01,  2.6369e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 1.8904e-01,  9.8524e-01, -2.4783e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [-5.3874e-01,  8.0857e-01,  6.0052e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          ...,\n",
              "          [-1.9610e+00,  2.0403e+00, -9.4904e-02,  ...,  2.4274e-01,\n",
              "                  -inf,        -inf],\n",
              "          [ 1.0505e+00, -3.5816e-01,  5.7286e-02,  ...,  1.1878e+00,\n",
              "            5.8422e-01,        -inf],\n",
              "          [-1.1507e+00,  1.0112e+00,  8.4346e-01,  ..., -3.3573e-02,\n",
              "            8.2581e-02,  2.7142e-01]],\n",
              "\n",
              "         [[ 4.0810e+00, -2.3358e-01, -5.2964e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [-1.4827e+00, -1.4111e+00, -5.6822e-02,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 4.6090e+00,  6.0202e-01, -6.7777e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          ...,\n",
              "          [-2.1547e+00, -9.7678e-01,  8.4515e-01,  ...,  7.0300e-01,\n",
              "                  -inf,        -inf],\n",
              "          [ 1.9367e+00, -5.6875e-01,  4.2419e-02,  ..., -2.2981e-01,\n",
              "            8.0465e-01,        -inf],\n",
              "          [ 2.6025e+00,  8.4701e-01, -1.5224e+00,  ...,  6.6412e-01,\n",
              "            9.3719e-01,  1.1339e+00]]],\n",
              "\n",
              "\n",
              "        [[[ 1.8251e-01,  2.3801e+00,  3.4547e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 9.9521e-01, -3.3068e+00, -2.5664e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 7.3090e-01, -2.1111e+00, -3.8685e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          ...,\n",
              "          [ 1.0938e+00, -5.4507e-02, -3.3546e+00,  ..., -1.9419e+00,\n",
              "                  -inf,        -inf],\n",
              "          [ 9.7305e-01,  3.3857e+00,  1.3380e+00,  ..., -9.2128e-01,\n",
              "            7.8254e-01,        -inf],\n",
              "          [ 2.2924e+00, -7.5129e-01, -2.8958e+00,  ..., -1.7732e+00,\n",
              "            1.1954e+00, -5.8606e-01]],\n",
              "\n",
              "         [[ 1.8712e+00,  1.4436e+00,  4.8291e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [-6.9877e-01, -1.9077e-02, -5.2843e-02,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [-3.5021e+00, -1.8723e+00,  2.1864e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          ...,\n",
              "          [-1.6041e+00,  1.2683e-02, -2.7460e+00,  ...,  5.6502e-01,\n",
              "                  -inf,        -inf],\n",
              "          [-2.2787e+00, -4.4111e-01, -1.0903e-01,  ..., -1.8644e-01,\n",
              "            2.6585e-01,        -inf],\n",
              "          [ 9.1523e-01, -9.0998e-03, -7.6647e-01,  ..., -1.7106e-01,\n",
              "            6.1523e-01,  7.9388e-01]],\n",
              "\n",
              "         [[ 1.3151e+00,  9.3215e-01, -1.6536e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 3.2440e-01, -1.1642e+00, -6.7389e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 2.2796e+00,  3.8670e+00,  8.0282e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          ...,\n",
              "          [-4.3008e-01,  5.2783e-01,  2.4920e+00,  ...,  1.0807e+00,\n",
              "                  -inf,        -inf],\n",
              "          [ 2.6245e+00,  3.5083e+00,  4.2259e-01,  ...,  9.4350e-01,\n",
              "           -1.4371e-01,        -inf],\n",
              "          [ 6.9866e-02, -2.0454e+00, -3.8523e-01,  ...,  6.9809e-01,\n",
              "           -9.1099e-02,  5.4403e-01]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 5.3347e-01, -2.1600e+00, -1.7180e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [-6.0803e-01, -5.7273e-01, -7.2803e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 1.1148e-01,  8.2102e-01, -4.2665e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          ...,\n",
              "          [-2.1713e+00,  2.8526e+00, -1.1779e-01,  ...,  2.1803e+00,\n",
              "                  -inf,        -inf],\n",
              "          [-4.4238e-01, -1.7414e+00,  1.2477e+00,  ...,  2.4931e+00,\n",
              "           -5.8306e-01,        -inf],\n",
              "          [-5.7045e-01, -2.4810e+00, -1.0764e+00,  ...,  1.9624e+00,\n",
              "           -2.0920e-01, -1.5158e-01]],\n",
              "\n",
              "         [[ 1.3474e+00, -1.4216e+00, -9.6472e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [-3.9483e-01,  2.1747e-01, -2.8711e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [-2.4714e+00,  6.1418e-01, -9.1417e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          ...,\n",
              "          [-1.6461e-01,  9.3701e-01,  2.2945e+00,  ...,  8.2315e-01,\n",
              "                  -inf,        -inf],\n",
              "          [ 2.7162e-02,  3.3224e-02,  9.8080e-01,  ...,  1.6751e+00,\n",
              "           -1.0688e+00,        -inf],\n",
              "          [ 1.6686e+00, -5.4301e-01,  1.0872e+00,  ...,  1.2065e+00,\n",
              "            7.6587e-01,  1.2135e-01]],\n",
              "\n",
              "         [[-8.3289e-01,  7.8377e-01, -1.2131e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 8.3154e-01, -4.7982e-01, -4.9723e-02,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 6.3001e-01, -2.7281e+00,  8.3032e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          ...,\n",
              "          [ 4.5516e-01,  4.1332e-01,  1.1021e+00,  ...,  1.9246e+00,\n",
              "                  -inf,        -inf],\n",
              "          [ 6.1242e-02, -1.5100e+00,  2.5149e+00,  ..., -8.9098e-01,\n",
              "            3.2449e-01,        -inf],\n",
              "          [ 1.5584e-01, -1.7088e+00,  9.4196e-01,  ...,  9.3086e-01,\n",
              "           -1.3584e+00, -2.7963e-01]]],\n",
              "\n",
              "\n",
              "        ...,\n",
              "\n",
              "\n",
              "        [[[-6.9961e-01, -1.3461e+00, -8.7529e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 5.1168e-01, -3.2287e-01,  5.4050e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 1.2817e+00, -3.0783e+00, -7.0882e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          ...,\n",
              "          [-8.2463e-01, -1.9123e-01,  8.0414e-01,  ...,  3.1488e-01,\n",
              "                  -inf,        -inf],\n",
              "          [-1.5863e+00, -3.2132e-01,  9.5625e-01,  ...,  1.6460e+00,\n",
              "            1.0984e+00,        -inf],\n",
              "          [ 2.2953e+00,  3.5332e+00,  1.9037e+00,  ...,  1.6847e+00,\n",
              "            4.2487e-01, -6.0397e-01]],\n",
              "\n",
              "         [[-2.4494e+00, -3.4050e-01, -2.6731e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 1.8533e+00,  2.5486e+00,  2.5426e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [-1.2636e+00,  8.3683e-01, -1.0484e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          ...,\n",
              "          [ 1.2437e+00,  2.0723e+00,  3.6378e+00,  ...,  1.5712e-01,\n",
              "                  -inf,        -inf],\n",
              "          [ 4.1380e-01,  6.9899e-01,  3.2315e+00,  ...,  7.2909e-02,\n",
              "           -1.4690e+00,        -inf],\n",
              "          [-1.9894e-01, -4.0724e+00, -2.0931e+00,  ...,  4.9264e-01,\n",
              "            6.5862e-01,  1.4828e+00]],\n",
              "\n",
              "         [[-5.1348e+00, -1.0608e-02, -5.5273e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [-1.7162e+00, -1.4286e+00, -4.1916e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 3.5079e-02, -5.4646e-01, -6.4010e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          ...,\n",
              "          [ 2.3007e+00, -2.2800e-01,  1.3648e+00,  ...,  9.4742e-01,\n",
              "                  -inf,        -inf],\n",
              "          [ 2.9570e+00,  2.3890e+00,  4.9822e+00,  ...,  5.1478e-01,\n",
              "           -3.4059e-01,        -inf],\n",
              "          [-6.7000e-01, -1.0791e+00, -3.9581e+00,  ..., -7.8893e-01,\n",
              "           -1.8339e+00,  6.3388e-01]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 2.6514e+00,  1.2142e+00, -1.2953e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [-1.0114e+00, -1.4424e+00,  3.7917e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 1.8727e+00,  2.1153e-01, -8.8288e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          ...,\n",
              "          [ 7.0595e-01, -1.4856e+00, -3.2522e-01,  ..., -5.3337e-01,\n",
              "                  -inf,        -inf],\n",
              "          [ 2.2075e-01, -1.0549e+00, -1.0444e+00,  ..., -4.0919e-01,\n",
              "            4.1303e-01,        -inf],\n",
              "          [ 2.7994e+00,  1.5642e+00, -2.3711e+00,  ...,  5.7702e-01,\n",
              "           -3.4884e-01,  1.5184e+00]],\n",
              "\n",
              "         [[-2.4787e+00,  1.0473e+00,  8.7155e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [-8.0964e-01, -7.7780e-01, -3.2505e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 1.7044e+00,  2.9143e-01, -2.6816e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          ...,\n",
              "          [-5.8195e-01, -1.6146e+00, -1.2421e+00,  ...,  3.0312e-01,\n",
              "                  -inf,        -inf],\n",
              "          [-3.1798e-01,  2.1821e-01, -2.0988e+00,  ...,  2.7805e-01,\n",
              "            2.6610e-01,        -inf],\n",
              "          [ 1.8917e+00, -4.6698e+00,  2.4381e+00,  ..., -3.6625e-01,\n",
              "           -3.7590e-01, -7.1155e-01]],\n",
              "\n",
              "         [[-1.2834e+00, -2.8448e-01,  2.1115e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 2.2453e-02, -8.0373e-01, -7.3416e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 2.4603e+00,  1.7867e+00,  7.5437e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          ...,\n",
              "          [-1.4543e+00, -1.8532e-01, -3.5514e-01,  ..., -2.4199e-01,\n",
              "                  -inf,        -inf],\n",
              "          [-1.1118e+00,  1.1021e+00,  1.9267e+00,  ..., -6.8310e-01,\n",
              "           -1.9002e-01,        -inf],\n",
              "          [ 7.2954e-02,  1.0439e+00, -8.7178e-01,  ..., -3.5306e-01,\n",
              "           -1.2387e+00, -1.2799e-01]]],\n",
              "\n",
              "\n",
              "        [[[-1.5349e-01,  2.2037e+00,  1.5828e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [-1.7370e+00,  3.0261e-01, -3.9187e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [-2.4269e+00, -1.4387e-01,  8.2062e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          ...,\n",
              "          [-7.4705e-01, -1.8820e-01, -1.8646e-01,  ...,  2.3377e-01,\n",
              "                  -inf,        -inf],\n",
              "          [-1.4059e+00,  9.8251e-01,  1.2953e+00,  ...,  1.6182e-01,\n",
              "            3.9855e-01,        -inf],\n",
              "          [ 6.5286e-01, -6.9346e-01,  1.9893e-02,  ..., -9.6624e-02,\n",
              "            1.7690e-03,  3.7695e-01]],\n",
              "\n",
              "         [[-5.0608e-01, -4.8005e-01,  7.3683e-02,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 2.8457e-01,  2.0028e+00,  1.3929e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 1.2654e+00,  1.2632e+00,  1.5456e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          ...,\n",
              "          [ 4.9739e-01, -9.3843e-01, -8.7748e-01,  ..., -1.8187e-01,\n",
              "                  -inf,        -inf],\n",
              "          [ 4.4508e-01, -2.6552e+00, -1.6744e+00,  ...,  1.2998e-01,\n",
              "           -7.6071e-02,        -inf],\n",
              "          [ 7.1869e-01,  3.8153e-01,  3.3193e+00,  ...,  1.2997e-02,\n",
              "           -7.8879e-01,  3.9699e-01]],\n",
              "\n",
              "         [[ 3.4049e-01,  2.0626e-01,  1.3601e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [-9.8374e-01,  1.3733e+00, -3.4035e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [-1.9068e+00,  3.5218e+00,  6.9792e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          ...,\n",
              "          [ 1.1319e-01,  6.0464e-01, -2.0733e-01,  ..., -6.5653e-03,\n",
              "                  -inf,        -inf],\n",
              "          [-2.9512e-01,  9.4583e-01,  6.7626e-01,  ..., -9.6130e-02,\n",
              "            2.7722e-01,        -inf],\n",
              "          [ 7.5643e-01,  1.2550e+00,  1.7836e+00,  ..., -1.2722e+00,\n",
              "           -2.0571e+00, -2.8422e-02]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[-8.7985e-01,  1.4368e+00,  7.9541e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [-1.1608e+00, -1.3274e+00,  2.3884e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [-2.5118e-01,  1.2896e+00,  3.6287e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          ...,\n",
              "          [ 2.2820e-01,  7.8308e-01,  4.3175e-01,  ..., -9.3029e-01,\n",
              "                  -inf,        -inf],\n",
              "          [-7.9377e-01, -9.5162e-02,  9.5611e-01,  ..., -1.6399e+00,\n",
              "           -1.1862e+00,        -inf],\n",
              "          [ 1.2736e+00,  1.1114e+00,  2.7031e+00,  ..., -3.4299e-01,\n",
              "           -9.3421e-01, -7.2754e-01]],\n",
              "\n",
              "         [[ 1.4388e-01, -2.1003e+00, -2.0629e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [-2.2096e-01,  4.0808e-01, -3.9685e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 1.1718e-01, -2.0926e+00, -1.0265e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          ...,\n",
              "          [ 5.0619e-01,  1.6047e+00,  1.8299e+00,  ...,  8.4444e-01,\n",
              "                  -inf,        -inf],\n",
              "          [-4.9898e-02,  1.1082e+00,  6.9385e-01,  ...,  9.1901e-01,\n",
              "            6.6390e-01,        -inf],\n",
              "          [-1.6426e-03,  1.6929e+00,  3.8796e+00,  ...,  5.0996e-02,\n",
              "           -4.1694e-01,  2.4252e-01]],\n",
              "\n",
              "         [[ 6.9660e-01,  2.5868e-01,  1.8929e-02,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [-1.4620e+00, -2.5203e+00, -4.8326e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 2.1410e-01,  8.0273e-01,  3.1438e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          ...,\n",
              "          [ 1.5092e+00,  1.9240e+00,  2.1139e+00,  ...,  3.5472e-01,\n",
              "                  -inf,        -inf],\n",
              "          [ 3.8202e+00,  3.3505e+00,  1.1728e+00,  ...,  1.7216e-02,\n",
              "           -6.7217e-01,        -inf],\n",
              "          [-3.2772e+00,  1.0267e+00, -1.7645e-01,  ...,  1.4538e+00,\n",
              "            1.9990e+00,  1.8870e+00]]],\n",
              "\n",
              "\n",
              "        [[[-3.5054e+00, -4.0208e+00, -3.4110e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 1.3111e+00, -5.9898e-01,  1.6370e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 4.4259e+00,  3.9533e+00,  2.1940e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          ...,\n",
              "          [-2.3611e+00, -2.2558e+00, -3.3683e+00,  ..., -3.7720e+00,\n",
              "                  -inf,        -inf],\n",
              "          [-3.1875e+00, -3.0465e+00, -3.2811e+00,  ..., -3.7964e+00,\n",
              "           -1.7461e+00,        -inf],\n",
              "          [ 1.5335e+00,  1.3158e+00,  2.0807e+00,  ...,  1.1482e+00,\n",
              "           -3.6854e-01, -1.6551e-01]],\n",
              "\n",
              "         [[ 1.3835e+00, -1.6743e+00,  1.9142e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [-3.3779e-01,  2.2286e-01, -5.4535e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [-3.6456e+00,  2.0125e+00, -4.9779e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          ...,\n",
              "          [ 2.3439e+00,  3.9499e-01,  1.8606e+00,  ...,  1.0477e+00,\n",
              "                  -inf,        -inf],\n",
              "          [ 1.6567e+00, -1.0805e+00,  2.3601e+00,  ...,  1.0484e+00,\n",
              "            4.4169e-01,        -inf],\n",
              "          [-2.4569e-01,  1.1450e+00, -2.2026e+00,  ..., -1.6965e-02,\n",
              "           -8.2940e-01,  4.6884e-01]],\n",
              "\n",
              "         [[-2.2633e+00, -1.0365e+00, -1.6906e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 3.3905e+00, -1.3537e+00,  1.1253e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 2.3305e+00, -3.5565e+00,  9.6783e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          ...,\n",
              "          [-1.2489e+00,  1.7047e+00,  3.8685e-01,  ..., -1.2503e+00,\n",
              "                  -inf,        -inf],\n",
              "          [-4.4122e+00, -3.4163e-01, -3.1569e-02,  ...,  2.8820e+00,\n",
              "            4.3519e+00,        -inf],\n",
              "          [ 3.0928e+00, -1.6570e+00,  1.0455e+00,  ..., -7.9464e-01,\n",
              "           -2.4973e+00,  2.3907e+00]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 2.4731e+00, -4.0588e-02, -2.2242e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 5.2053e-01, -5.6783e-01, -2.6634e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 2.9807e+00,  1.1124e+00,  1.9369e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          ...,\n",
              "          [ 1.4089e+00,  3.5411e+00,  2.6537e-01,  ...,  1.5973e-01,\n",
              "                  -inf,        -inf],\n",
              "          [ 4.0939e-01,  4.3110e+00, -2.4174e+00,  ..., -1.4875e+00,\n",
              "           -1.0115e+00,        -inf],\n",
              "          [-1.4427e+00,  2.4194e+00, -2.8105e+00,  ..., -5.2016e-01,\n",
              "           -2.1116e+00,  8.7757e-01]],\n",
              "\n",
              "         [[-1.3582e+00,  8.1157e-01, -9.0788e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [-3.5202e+00, -2.1941e+00,  1.4375e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 7.4899e+00,  1.5644e+00, -1.8472e-01,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          ...,\n",
              "          [-4.5431e+00, -7.2640e-01,  9.1451e-02,  ...,  1.0166e+00,\n",
              "                  -inf,        -inf],\n",
              "          [-6.7775e+00,  7.4890e-01,  5.3588e-01,  ..., -6.6438e-02,\n",
              "           -1.2718e+00,        -inf],\n",
              "          [-3.3760e-01, -3.2237e+00, -6.6209e-01,  ..., -6.9522e-02,\n",
              "           -1.0527e+00,  3.3074e-01]],\n",
              "\n",
              "         [[-1.8177e+00, -1.4782e+00,  3.2916e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 1.2909e+00, -1.9861e+00,  1.2943e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          [ 2.5897e+00, -1.7185e+00, -2.2618e+00,  ...,        -inf,\n",
              "                  -inf,        -inf],\n",
              "          ...,\n",
              "          [-3.4182e+00,  1.7850e+00,  1.7366e+00,  ..., -2.9812e-01,\n",
              "                  -inf,        -inf],\n",
              "          [-1.0106e+00, -3.5117e-01,  1.0933e+00,  ..., -1.8462e+00,\n",
              "            8.9907e-01,        -inf],\n",
              "          [ 1.9751e+00, -1.3480e+00,  9.2876e-02,  ...,  5.4113e-01,\n",
              "           -1.3227e+00,  1.7300e+00]]]], grad_fn=<MaskedFillBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply softmax\n",
        "qk = F.softmax(qk, dim=-1)\n",
        "qk[0][0][0].sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvogCqCOkoLn",
        "outputId": "a9f01413-9639-47e7-e63b-88a94d8e4264"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1., grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate values tensor into heads for multi-head attention and move dimensions for @ with qk\n",
        "values = rearrange(values, 'b t (h d) -> b h t d', h=number_heads)\n",
        "print (\"qk:\", qk.shape)\n",
        "print (\"values:\", values.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVDMqb7ykrEx",
        "outputId": "d067dddf-00dd-45d0-8dd6-ffcd62650871"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "qk: torch.Size([16, 8, 512, 1024])\n",
            "values: torch.Size([16, 8, 1024, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qkv = qk@values\n",
        "qkv.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSrTW6xCkv5n",
        "outputId": "d9c82412-a860-4c77-d9b8-a39202864779"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 8, 512, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reassemble all heads\n",
        "qkv = rearrange(qkv, 'b h t d -> b t (h d)')\n",
        "qkv.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHKZHGfyk96U",
        "outputId": "12e3c42e-27ca-4345-c65c-f86ad03cb2e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 512, 80])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTMQvxxwlACh",
        "outputId": "58ab1153-720b-4afc-8c00-5c500e200178"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=80, out_features=13, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = output_matrix(qkv)\n",
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi_tOKnNlEZJ",
        "outputId": "f43d3b3b-9b36-4390-bf4d-ea538b5bb997"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 512, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class XLAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_dimension,\n",
        "        heads = 8,\n",
        "        head_dimension = 32,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.heads = heads\n",
        "        self.scale = head_dimension ** -0.5\n",
        "\n",
        "        self.query_matrix = nn.Linear(embedding_dimension, heads * head_dimension)\n",
        "        self.key_matrix = nn.Linear(embedding_dimension, heads * head_dimension)\n",
        "        self.value_matrix = nn.Linear(embedding_dimension, heads * head_dimension)\n",
        "        self.output_matrix = nn.Linear(heads * head_dimension, embedding_dimension)\n",
        "\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        x, # batch_size, sequence_length, embedding_dimension\n",
        "        xl_memory = None\n",
        "    ):\n",
        "        batch_size, sequence_length = x.shape[:2]\n",
        "        queries = self.query_matrix(x)\n",
        "        keys = self.key_matrix(x)\n",
        "        values = self.value_matrix(x)\n",
        "\n",
        "        if xl_memory is not None:\n",
        "            k_xl, v_xl = xl_memory.unbind(dim=-2) # unstack\n",
        "            keys = torch.cat((k_xl, keys), dim = -2) # prepend XL memory\n",
        "            values = torch.cat((v_xl, values), dim = -2) # prepend XL memory\n",
        "            xl_sequence_length = k_xl.shape[1]\n",
        "\n",
        "        queries = rearrange(queries, 'b t (h d) -> b h t d', h = self.heads)\n",
        "        keys    = rearrange(keys, 'b t (h d) -> b h t d', h = self.heads)\n",
        "        qk      = einsum(queries, keys, 'b h i d, b h j d -> b h i j')\n",
        "\n",
        "        qk = qk * self.scale\n",
        "\n",
        "        i, j = qk.shape[-2:]\n",
        "        mask = torch.ones((i,j), dtype = torch.bool).triu(j-i+1)\n",
        "        qk = qk.masked_fill(mask, float('-inf'))\n",
        "\n",
        "        qk = F.softmax(qk, dim=-1)\n",
        "\n",
        "        values = rearrange(values, 'b t (h d) -> b h t d', h=self.heads)\n",
        "        qkv = qk@values\n",
        "        qkv = rearrange(qkv, 'b h t d -> b t (h d)')\n",
        "\n",
        "        #### Return XL Memories\n",
        "\n",
        "        keys = rearrange(keys, 'b h t d -> b t (h d)', h = self.heads)\n",
        "        values = rearrange(values, 'b h t d -> b t (h d)', h=self.heads)\n",
        "        kv_memories = torch.stack((keys, values), dim=-2) # (batch, sequence_len, 2, dimension)\n",
        "\n",
        "        if xl_memory is not None: #pass on the keys and values so that next segment can use these projections\n",
        "            xl_memories, current_input = kv_memories[:, :-xl_sequence_length], kv_memories[:, -xl_sequence_length:]\n",
        "            kv_to_add_xl = current_input\n",
        "        else:\n",
        "            kv_to_add_xl = kv_memories\n",
        "\n",
        "\n",
        "        out = self.output_matrix(qkv)\n",
        "\n",
        "\n",
        "\n",
        "        return out, kv_to_add_xl\n"
      ],
      "metadata": {
        "id": "i6CYdO8PlGgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KNN_XLAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_dimension,\n",
        "        heads = 8,\n",
        "        head_dimension = 32,\n",
        "        topk_retrieved_memories = 3,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.heads = heads\n",
        "        self.scale = head_dimension ** -0.5\n",
        "\n",
        "        self.query_matrix = nn.Linear(embedding_dimension, heads * head_dimension)\n",
        "        self.key_matrix = nn.Linear(embedding_dimension, heads * head_dimension)\n",
        "        self.value_matrix = nn.Linear(embedding_dimension, heads * head_dimension)\n",
        "        self.output_matrix = nn.Linear(heads * head_dimension, embedding_dimension)\n",
        "\n",
        "        self.gate_bias = nn.Parameter(torch.randn(self.heads, 1, 1))\n",
        "        self.topk_retrieved_memories = topk_retrieved_memories\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        x, # batch_size, sequence_length, embedding_dimension\n",
        "        knn,\n",
        "        xl_memory = None\n",
        "    ):\n",
        "        batch_size, sequence_length = x.shape[:2]\n",
        "        queries = self.query_matrix(x)\n",
        "        keys = self.key_matrix(x)\n",
        "        values = self.value_matrix(x)\n",
        "\n",
        "        if xl_memory is not None:\n",
        "            k_xl, v_xl = xl_memory.unbind(dim = -2) # unstack\n",
        "            keys = torch.cat((k_xl, keys), dim = -2) # prepend XL memory\n",
        "            values = torch.cat((v_xl, values), dim = -2) # prepend XL memory\n",
        "            xl_sequence_length = k_xl.shape[1]\n",
        "\n",
        "        ### LOCAL ATTENTION\n",
        "\n",
        "        queries = rearrange(queries, 'b t (h d) -> b h t d', h = self.heads)\n",
        "        keys    = rearrange(keys, 'b t (h d) -> b h t d', h = self.heads)\n",
        "        qk      = einsum(queries, keys, 'b h i d, b h j d -> b h i j')\n",
        "\n",
        "        qk = qk * self.scale\n",
        "\n",
        "        ############\n",
        "        # TODO\n",
        "        # qk = relative_position_values + qk\n",
        "        ############\n",
        "\n",
        "        i, j = qk.shape[-2:]\n",
        "        mask = torch.ones((i,j), dtype = torch.bool).triu(j-i+1)\n",
        "        qk = qk.masked_fill(mask, float('-inf'))\n",
        "\n",
        "        qk = F.softmax(qk, dim=-1)\n",
        "\n",
        "        values = rearrange(values, 'b t (h d) -> b h t d', h=self.heads)\n",
        "        qkv = qk@values\n",
        "        qkv = rearrange(qkv, 'b h t d -> b t (h d)')\n",
        "\n",
        "        ### KNN ATTENTION\n",
        "\n",
        "        # Convert queries to search form\n",
        "        queries = rearrange(queries, 'b h t d -> b t (h d)')\n",
        "        mem_kv = knn.search(queries, topk = self.topk_retrieved_memories) # returns b t k 2 d\n",
        "        mem_k, mem_v = mem_kv.unbind(dim = -2)\n",
        "        mem_k = rearrange(mem_k, 'b t k (h d) -> b h t k d', h=self.heads)\n",
        "        mem_v = rearrange(mem_v, 'b t k (h d) -> b h t k d', h=self.heads)\n",
        "\n",
        "        # Convert queries to attention form\n",
        "        queries = rearrange(queries, 'b t (h d) -> b h t d', h = self.heads)\n",
        "        mem_qk = einsum('b h t d, b h t k d -> b h t k', queries, mem_k)\n",
        "        mem_qk = mem_qk * self.scale\n",
        "\n",
        "        mem_qk = F.softmax(mem_qk, dim=-1)\n",
        "        mem_qk = self.dropout(mem_qk)\n",
        "        mem_qkv = einsum('b h t k, b h t k d -> b h t d', mem_qk, mem_v)\n",
        "\n",
        "        # Combined attentions\n",
        "\n",
        "        combined_qkv = mem_qkv * self.gate_bias + qkv * (1 - self.gate_bias)\n",
        "        combined_qkv = rearrange(combined_qkv, 'b h t d -> b t (h d)')\n",
        "        out = self.output_matrix(combined_qkv)\n",
        "\n",
        "        # New XL memories\n",
        "        keys = rearrange(keys, 'b h t d -> b t (h d)', h = self.heads)\n",
        "        values = rearrange(values, 'b h t d -> b t (h d)', h=self.heads)\n",
        "        kv_memories = torch.stack((keys, values), dim=-2) # (batch, sequence_len, 2, dimension)\n",
        "\n",
        "        if xl_memory is not None:\n",
        "            # if we're on a middle/end segment of a document (there are previous XL memories)\n",
        "            xl_memories, current_kv = kv_memories[:, :-xl_sequence_length], kv_memories[:, -xl_sequence_length:]\n",
        "        else:\n",
        "            # if we're at the first segment\n",
        "            current_kv = kv_memories\n",
        "\n",
        "        knn.add(current_kv)\n",
        "\n",
        "        return out, current_kv"
      ],
      "metadata": {
        "id": "pHNUdo8ilPVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TEsUcwO0m6Ea"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}