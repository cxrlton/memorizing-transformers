{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dbe14c0efe584754ab94d2b701324bc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dad4c59aea9d4e3cafd38fe18ad28acf",
              "IPY_MODEL_33e926250bfc47ec8489d33a9f3047bd",
              "IPY_MODEL_8b4188f6f1fb4e548b8aaf2887911d5b"
            ],
            "layout": "IPY_MODEL_1641130a588a489fb393246df31ec949"
          }
        },
        "dad4c59aea9d4e3cafd38fe18ad28acf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50888f89b8fc492391dacf23f1a13b63",
            "placeholder": "​",
            "style": "IPY_MODEL_256ac09874c349688c120f68affb4e6a",
            "value": "README.md: 100%"
          }
        },
        "33e926250bfc47ec8489d33a9f3047bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c333e0e588243ff857016360e4e5121",
            "max": 3965,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3bd64d249c1f4d4a985c8a8ebc92f342",
            "value": 3965
          }
        },
        "8b4188f6f1fb4e548b8aaf2887911d5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e2cd634860641e0abc1a463f18b1595",
            "placeholder": "​",
            "style": "IPY_MODEL_e8d50119cca240c69c5fedccd06ee2b9",
            "value": " 3.96k/3.96k [00:00&lt;00:00, 98.2kB/s]"
          }
        },
        "1641130a588a489fb393246df31ec949": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50888f89b8fc492391dacf23f1a13b63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "256ac09874c349688c120f68affb4e6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c333e0e588243ff857016360e4e5121": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bd64d249c1f4d4a985c8a8ebc92f342": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e2cd634860641e0abc1a463f18b1595": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8d50119cca240c69c5fedccd06ee2b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9vev5GN8sBq",
        "outputId": "71397f6f-e08e-4b1c-baff-76b7d9f2d0e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "!pip3 install datasets\n",
        "import datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.load_dataset(\"ccdv/arxiv-summarization\", split = \"train\", streaming = True) #acts like a generator; takes data as you call for it\n",
        "raw_dataset = list(dataset.take(3500))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176,
          "referenced_widgets": [
            "dbe14c0efe584754ab94d2b701324bc4",
            "dad4c59aea9d4e3cafd38fe18ad28acf",
            "33e926250bfc47ec8489d33a9f3047bd",
            "8b4188f6f1fb4e548b8aaf2887911d5b",
            "1641130a588a489fb393246df31ec949",
            "50888f89b8fc492391dacf23f1a13b63",
            "256ac09874c349688c120f68affb4e6a",
            "8c333e0e588243ff857016360e4e5121",
            "3bd64d249c1f4d4a985c8a8ebc92f342",
            "6e2cd634860641e0abc1a463f18b1595",
            "e8d50119cca240c69c5fedccd06ee2b9"
          ]
        },
        "id": "LeE8XcZdAIuO",
        "outputId": "b437b939-0519-4727-8aef-a2c81b5d7506"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/3.96k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dbe14c0efe584754ab94d2b701324bc4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BATCH SIZE: 4 (papers)\n",
        "# CHUNK SIZE: 5 (each paper broken into 5 chunks of n tokens each)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#        forward pass 1 | FP 2    | FP 3    | FP 4    | FP 5    |\n",
        "#\n",
        "# paper 1:      chunk 1 | chunk 2 | chunk 3 | chunk 4 | chunk 5 |\n",
        "# paper 2:      chunk 1 | chunk 2 | chunk 3 | chunk 4 | chunk 5 |\n",
        "# paper 3:      chunk 1 | chunk 2 | chunk 3 | chunk 4 | chunk 5 |\n",
        "# paper 4:      chunk 1 | chunk 2 | chunk 3 | chunk 4 | chunk 5 |\n",
        "#\n",
        "#\n",
        "#\n",
        "#        forward pass 6 | FP 7    | FP 8    | FP 9    | FP 10   |\n",
        "#\n",
        "# paper 5:      chunk 1 | chunk 2 | chunk 3 | chunk 4 | chunk 5 |\n",
        "# paper 6:      chunk 1 | chunk 2 | chunk 3 | chunk 4 | chunk 5 |\n",
        "# paper 7:      chunk 1 | chunk 2 | chunk 3 | chunk 4 | chunk 5 |\n",
        "# paper 8:      chunk 1 | chunk 2 | chunk 3 | chunk 4 | chunk 5 |\n"
      ],
      "metadata": {
        "id": "-iYJgyvwA72f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "segments = 10\n",
        "segment_length = 512 #feed 512 tokens to the model\n",
        "chunk_size = segments * segment_length\n",
        "chunk_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToJfNcSsBeAP",
        "outputId": "99ab4784-cd5f-42d7-ac63-e845213a5f03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5120"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_articles = [x['article'] for x in raw_dataset]\n",
        "raw_articles = [x for x in raw_articles if len(x) > 5120]"
      ],
      "metadata": {
        "id": "dQ7sW4QyB-IU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"number of articles\", len(raw_articles))\n",
        "\n",
        "unique_chars = set(''.join([i for i in raw_articles]))\n",
        "print(\"character set length\", len(unique_chars))\n",
        "print(\"character set\", ''.join(sorted(unique_chars)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyhRSRNLCwJi",
        "outputId": "20094b8e-2e68-47fe-872d-fa4bd929925a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of articles 3401\n",
            "character set length 70\n",
            "character set \n",
            " !\"#$%&'()*+,-./0123456789:;<=>?@[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.fromstring(raw_articles[0], dtype = np.uint8)[:512] #character set being mapped to 128 integers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T16k9toIC0sN",
        "outputId": "8df0afe0-3a0e-40bc-e331-c5c37e367111"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-292acdd9a5c1>:1: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
            "  np.fromstring(raw_articles[0], dtype = np.uint8)[:512] #character set being mapped to 128 integers\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 97, 100, 100, 105, 116, 105, 118, 101,  32, 109, 111, 100, 101,\n",
              "       108, 115,  32,  64, 120,  99, 105, 116, 101,  32, 112, 114, 111,\n",
              "       118, 105, 100, 101,  32,  97, 110,  32, 105, 109, 112, 111, 114,\n",
              "       116,  97, 110, 116,  32, 102,  97, 109, 105, 108, 121,  32, 111,\n",
              "       102,  32, 109, 111, 100, 101, 108, 115,  32, 102, 111, 114,  32,\n",
              "       115, 101, 109, 105, 112,  97, 114,  97, 109, 101, 116, 114, 105,\n",
              "        99,  32, 114, 101, 103, 114, 101, 115, 115, 105, 111, 110,  32,\n",
              "       111, 114,  32,  99, 108,  97, 115, 115, 105, 102, 105,  99,  97,\n",
              "       116, 105, 111, 110,  32,  46,  32, 115, 111, 109, 101,  32, 114,\n",
              "       101,  97, 115, 111, 110, 115,  32, 102, 111, 114,  32, 116, 104,\n",
              "       101,  32, 115, 117,  99,  99, 101, 115, 115,  32, 111, 102,  32,\n",
              "        97, 100, 100, 105, 116, 105, 118, 101,  32, 109, 111, 100, 101,\n",
              "       108, 115,  32,  97, 114, 101,  32, 116, 104, 101, 105, 114,  32,\n",
              "       105, 110,  99, 114, 101,  97, 115, 101, 100,  32, 102, 108, 101,\n",
              "       120, 105,  98, 105, 108, 105, 116, 121,  32, 119, 104, 101, 110,\n",
              "        32,  99, 111, 109, 112,  97, 114, 101, 100,  32, 116, 111,  32,\n",
              "       108, 105, 110, 101,  97, 114,  32, 111, 114,  32, 103, 101, 110,\n",
              "       101, 114,  97, 108, 105, 122, 101, 100,  32, 108, 105, 110, 101,\n",
              "        97, 114,  32, 109, 111, 100, 101, 108, 115,  32,  97, 110, 100,\n",
              "        32, 116, 104, 101, 105, 114,  32, 105, 110,  99, 114, 101,  97,\n",
              "       115, 101, 100,  32, 105, 110, 116, 101, 114, 112, 114, 101, 116,\n",
              "        97,  98, 105, 108, 105, 116, 121,  32, 119, 104, 101, 110,  32,\n",
              "        99, 111, 109, 112,  97, 114, 101, 100,  32, 116, 111,  32, 102,\n",
              "       117, 108, 108, 121,  32, 110, 111, 110, 112,  97, 114,  97, 109,\n",
              "       101, 116, 114, 105,  99,  32, 109, 111, 100, 101, 108, 115,  32,\n",
              "        46,  32,  10,  32, 105, 116,  32, 105, 115,  32, 119, 101, 108,\n",
              "       108,  32,  45,  32, 107, 110, 111, 119, 110,  32, 116, 104,  97,\n",
              "       116,  32, 103, 111, 111, 100,  32, 101, 115, 116, 105, 109,  97,\n",
              "       116, 111, 114, 115,  32, 105, 110,  32,  97, 100, 100, 105, 116,\n",
              "       105, 118, 101,  32, 109, 111, 100, 101, 108, 115,  32,  97, 114,\n",
              "       101,  32, 105, 110,  32, 103, 101, 110, 101, 114,  97, 108,  32,\n",
              "       108, 101, 115, 115,  32, 112, 114, 111, 110, 101,  32, 116, 111,\n",
              "        32, 116, 104, 101,  32,  99, 117, 114, 115, 101,  32, 111, 102,\n",
              "        32, 104, 105, 103, 104,  32, 100, 105, 109, 101, 110, 115, 105,\n",
              "       111, 110,  97, 108, 105, 116, 121,  32, 116, 104,  97, 110,  32,\n",
              "       103, 111, 111, 100,  32, 101, 115, 116, 105, 109,  97, 116, 111,\n",
              "       114, 115,  32, 105, 110,  32, 102, 117, 108, 108, 121,  32, 110,\n",
              "       111, 110, 112,  97, 114,  97, 109, 101, 116, 114, 105,  99,  32,\n",
              "       109, 111, 100, 101, 108, 115,  32,  46,  32,  10,  32, 109,  97,\n",
              "       110, 121,  32, 101, 120], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_text(tokens):\n",
        "  return ''.join([chr(i) for i in tokens])\n",
        "\n",
        "\n",
        "decode_text(np.fromstring(raw_articles[0], dtype = np.uint8)[:512])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "JmEzcle8Duhr",
        "outputId": "a134c614-8eb0-4a02-ec3d-5eba55483c29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-507a6a0e17f7>:5: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
            "  decode_text(np.fromstring(raw_articles[0], dtype = np.uint8)[:512])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'additive models @xcite provide an important family of models for semiparametric regression or classification . some reasons for the success of additive models are their increased flexibility when compared to linear or generalized linear models and their increased interpretability when compared to fully nonparametric models . \\n it is well - known that good estimators in additive models are in general less prone to the curse of high dimensionality than good estimators in fully nonparametric models . \\n many ex'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_articles[0][:512]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "fO0h-iQgE5Gx",
        "outputId": "de04b53b-f1a3-4f46-df56-8a08b15b3a9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'additive models @xcite provide an important family of models for semiparametric regression or classification . some reasons for the success of additive models are their increased flexibility when compared to linear or generalized linear models and their increased interpretability when compared to fully nonparametric models . \\n it is well - known that good estimators in additive models are in general less prone to the curse of high dimensionality than good estimators in fully nonparametric models . \\n many ex'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converted = [np.fromstring(doc, dtype=np.int8) for doc in raw_articles] #tokenized format"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6jXPSioE_hP",
        "outputId": "4bbe2350-5526-4f67-9c18-a5a493dcf405"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-35-f37bb218e19b>:1: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
            "  converted = [np.fromstring(doc, dtype=np.int8) for doc in raw_articles] #tokenized format\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clip_article(doc, chunk_size):\n",
        "    remainder = len(doc) % chunk_size\n",
        "    return doc[:-remainder] #removes last remainder tokens\n",
        "\n",
        "clipped = [clip_article(doc, 5120) for doc in converted]"
      ],
      "metadata": {
        "id": "QDbCfWZHjCKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clipped[1].shape[0] / 5120"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RH7WSjok7f0",
        "outputId": "ebd5dccd-df8a-4613-e08c-eac1ee3c031c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.0"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunked = [doc.reshape(-1, chunk_size) for doc in clipped] #chunks of clipped"
      ],
      "metadata": {
        "id": "0Jrxko6sk9a1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_data = torch.tensor(np.concatenate(chunked), dtype=torch.long)\n",
        "processed_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RaBrhjtj72_",
        "outputId": "7515c221-26a7-4406-96b1-ea8fe390cdb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20853, 5120])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eighty_split = int(processed_data.shape[0] * .8)\n",
        "ninety_split = int(processed_data.shape[0] * .9)"
      ],
      "metadata": {
        "id": "dA8WVKjlr5Ks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = iter(DataLoader(processed_data[:eighty_split], batch_size = 8, shuffle = True))\n",
        "val_loader = iter(DataLoader(processed_data[eighty_split:ninety_split], batch_size = 8, shuffle = True))\n",
        "test_loader = iter(DataLoader(processed_data[ninety_split:], batch_size = 8, shuffle = True))"
      ],
      "metadata": {
        "id": "EKyO_Ac9r3ly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = iter(DataLoader(processed_data, batch_size=8, shuffle=True))"
      ],
      "metadata": {
        "id": "AcANRWG8kFLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = next(loader)"
      ],
      "metadata": {
        "id": "uCl-k5t2muJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_3AwnSam3Gr",
        "outputId": "42ca88fe-2b3b-484c-c03f-7760ef8abe0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 5120])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq, labels = example[:, :-1], example[:, 1:]"
      ],
      "metadata": {
        "id": "iSm29kjcm361"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq[0][:15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27bw3XpvnCNt",
        "outputId": "8bc83ca6-3630-443a-bcd6-ed048bfe5108"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([103, 114,  97, 118, 105, 116,  97, 116, 105, 111, 110,  97, 108,  32,\n",
              "        108])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels[0][:15] #basically a shift by 1 (predicting next character)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_U-d3x8nazC",
        "outputId": "7fc729fd-e97e-46ec-8e12-7dfa5a872ba3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([114,  97, 118, 105, 116,  97, 116, 105, 111, 110,  97, 108,  32, 108,\n",
              "        101])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjXfaboJolao",
        "outputId": "0ed121ec-e5db-4cf8-806b-965272ea4008"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 5119])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq.chunk(10, dim=1)[0].shape #10 different traning sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RoLurPHngBj",
        "outputId": "f8673ffa-7ff2-4be6-bbc0-5284031a0c5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for seq_segment, labels_segment in zip(seq.chunk(10, dim = -1), labels.chunk(10, dim = -1)):\n",
        "    print(decode_text(seq_segment[1]), \"\\n *********** \\n\") #continuation of text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U65yfrLynr8M",
        "outputId": "b8707c7f-7d89-4ff7-a91a-5699946a2389"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "me masa @xmath0 in @xmath2 such that @xmath39    choose a masa @xmath141 such that @xmath9 belongs to @xmath141 . \n",
            " theorem ( [ shm1 ] ) yields that there is a unitary @xmath22 in @xmath68 and a projection @xmath43 in @xmath141 such that @xmath388 choose a masa @xmath389 in @xmath281 that contains @xmath289 . \n",
            " then , we have that @xmath390    note that we have that @xmath391 . \n",
            " let @xmath0 be the masa @xmath392 . \n",
            " we then get by applying the automorphism @xmath393 to the equation ( [ fc ] ) that @xmath39 \n",
            " *********** \n",
            "\n",
            "4 since @xmath395 , we are done . \n",
            " the above theorem , as remarked in the introduction , is a natural generalization of the schur - horn theorem to type @xmath1 factors . \n",
            " this generalization does not directly imply the alternative conjecture of arveson and kadison from @xcite . \n",
            " we prove the conjecture in full in the next section . \n",
            " we now turn to the second natural generalization of the schur - horn theorem . \n",
            " the theorem of the last section characterizes the spectral distributions of operators that  \n",
            " *********** \n",
            "\n",
            "arise as the `` diagonal '' of a given positive operator @xmath20 . on the other hand , \n",
            " the conjecture of arveson and kadison complements the abovementioned theorem by characterizing the spectral distributions of operators which have a prescribed diagonal @xmath9 . \n",
            " the calculations in this section are straightforward but technical . \n",
            " perhaps a few words about the idea of the proof might be helpful . \n",
            " let @xmath0 be a masa in type @xmath1 factor @xmath2 and let @xmath3 and @xmath40 be positive elements \n",
            " *********** \n",
            "\n",
            " so that @xmath19 . theorem ( [ shm1 ] ) in the last section says that there is a unitary @xmath22 and a projection @xmath43 so that if we write write out @xmath9 and @xmath23 in block matrix form with diagonal @xmath396 , @xmath397 then @xmath398 and @xmath399 inside @xmath103 and @xmath281 respectively . \n",
            " even though @xmath144 and @xmath146 are approximately unitarily equivalent inside @xmath281 , we can not expect to use these to implement an approximate unitary equivalence between @xmath23 and an opera \n",
            " *********** \n",
            "\n",
            "tor of the form @xmath400 . \n",
            " nevertheless , there is a workaround ; let us look closely at what @xmath19 means in terms of the spectral scales @xmath57 and @xmath69 . \n",
            " roughly speaking , @xmath401 is larger than @xmath402 for @xmath403 close to @xmath404 and smaller for @xmath403 close to @xmath356 . rather than work with @xmath9 and @xmath20 directly \n",
            " , we will work with @xmath405 and @xmath406 where @xmath43 and @xmath183 are carefully chosen spectral projections supported away from the extreme points  \n",
            " *********** \n",
            "\n",
            "of the spectra \n",
            " . we will apply theorem ( [ shm1 ] ) to @xmath405 and @xmath406 and might end up with pieces that are equimeasurable as above . \n",
            " we will then use the reserved head and tail of the spectra that we have hitherto left untouched to massage the equimeasurable parts carefully , in order to achieve the desired diagonal . \n",
            " the main result in this section is the proof of theorem ( [ conj2 ] ) . \n",
            " we first prove a couple of lemmas . \n",
            " we will use the notation @xmath407 to mean that @xmath408 for ev \n",
            " *********** \n",
            "\n",
            "ery @xmath76 $ ] . \n",
            " [ sht2lem ] let @xmath0 be a masa in a type @xmath1 factor @xmath2 and let @xmath3 and @xmath40 be two positive operators commuting with a projection @xmath43 of trace @xmath134 in @xmath0 , written with respect to the decomposition @xmath409 , @xmath410 where @xmath411 and @xmath412 and further , @xmath413 . then , for any @xmath414 , there is a unitary @xmath22 and projections @xmath415 and @xmath416 , both in @xmath0 , with @xmath417 for @xmath418 such that @xmath419 and @xmath420 .  \n",
            " *********** \n",
            "\n",
            "\n",
            " let @xmath421 be fixed . \n",
            " it is easy to see(using the fact that the spectral scales @xmath57 and @xmath69 are right continuous and non increasing ) that we may find a natural number @xmath422 , a number @xmath199 and disjoint intervals @xmath423 in @xmath64 $ ] with @xmath424 such that    1 . \n",
            " @xmath425 . and , 2 . \n",
            " @xmath426 for @xmath427 for @xmath428 . \n",
            " define the projections @xmath429 pick a unitary @xmath430 in @xmath103 that conjugates @xmath431 onto @xmath432 and a unitary @xmath433 in @xmath28 \n",
            " *********** \n",
            "\n",
            "1 that conjugates @xmath434 onto @xmath435 for @xmath428 . \n",
            " let @xmath436 and let @xmath437 . then , @xmath169 commutes with the projections @xmath432 and @xmath435 . for @xmath438 \n",
            " , let @xmath439 and @xmath440 . \n",
            " inside @xmath441 , we may write @xmath442 where @xmath443 and since , @xmath444 , we have that @xmath445 we see that for each @xmath428 , the pair of operators @xmath446 and @xmath447 inside @xmath441 satisfy the hypothesis of the remark following lemma([2matlem ] ) and we may thus find unitar \n",
            " *********** \n",
            "\n",
            "ies @xmath448 in @xmath441 such that @xmath449    let @xmath222 be a unitary in @xmath281 that conjugates @xmath450 onto @xmath451 for @xmath452 , i.e. @xmath453 . the second fact above gives us that    @xmath454    let @xmath22 be the unitary @xmath455 . also , let @xmath456 and @xmath457 . \n",
            " the two facts , ( [ fac1 ] ) and ( [ fac2 ] ) give us that @xmath458 finally , we have that @xmath459 and @xmath460 and both are greater than @xmath461 . we are done . \n",
            " [ eqmlem ] let @xmath0 be a masa in a type @xm \n",
            " *********** \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Embedding(128,16), # (vocab_size, embedding_dim)\n",
        "    nn.Linear(16, 150),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(150,150),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(150, 128), # (params, vocab_size)\n",
        ")\n",
        "\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.05)\n",
        "model.train()\n",
        "\n",
        "segments = 10\n",
        "\n",
        "for i in range(200):\n",
        "\n",
        "    data = next(train_loader) # (batch_size, sequence_length) # (8, 5120)\n",
        "    seq, labels = data[:, :-1], data[:, 1:]\n",
        "    train_loss = 0.\n",
        "    model.train()\n",
        "\n",
        "    for seq_segment, labels_segment in zip(seq.chunk(segments, dim = -1), labels.chunk(segments, dim = -1)): # ten passes of (8, 512)\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(seq_segment)\n",
        "        y_pred = y_pred.transpose(2,1)\n",
        "        loss = loss_fn(y_pred, labels_segment)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    if i % 5 == 0:\n",
        "        print (train_loss / segments)\n",
        "\n",
        "    if i > 0 and i % 50 == 0:\n",
        "        val_data = next(val_loader)\n",
        "        seq, labels = val_data[:, :-1], val_data[:, 1:]\n",
        "        eval_loss = 0.\n",
        "        model.eval()\n",
        "        for seq_segment, labels_segment in zip(seq.chunk(segments, dim = -1), labels.chunk(segments, dim = -1)): # ten passes of (8, 512)\n",
        "            with torch.no_grad():\n",
        "                y_pred = model(seq_segment)\n",
        "                y_pred = y_pred.transpose(2,1)\n",
        "                loss = loss_fn(y_pred, labels_segment)\n",
        "                eval_loss += loss.item()\n",
        "\n",
        "        print (\"VALIDATION LOSS\", (eval_loss / segments))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "scTIv8RvnxCx",
        "outputId": "327934ae-02cd-4f45-e4b1-bf29672fe064"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.76202802658081\n",
            "3.4509190559387206\n",
            "3.049196982383728\n",
            "3.031331992149353\n",
            "2.8706095457077025\n",
            "2.7924951314926147\n",
            "2.8087601184844972\n",
            "2.7336995601654053\n",
            "2.6220270872116087\n",
            "2.671736168861389\n",
            "2.622007131576538\n",
            "VALIDATION LOSS 2.842620325088501\n",
            "2.6414557456970216\n",
            "2.621060037612915\n",
            "2.5965858936309814\n",
            "2.6283721685409547\n",
            "2.538051629066467\n",
            "2.5659662961959837\n",
            "2.5906848907470703\n",
            "2.6154890298843383\n",
            "2.5480950593948366\n",
            "2.4774542808532716\n",
            "VALIDATION LOSS 2.8872291326522825\n",
            "2.4991343021392822\n",
            "2.534153127670288\n",
            "2.4870404958724976\n",
            "2.802467131614685\n",
            "2.418036699295044\n",
            "2.46250524520874\n",
            "2.4495493888854982\n",
            "2.4671412229537966\n",
            "2.608990263938904\n",
            "2.4182801246643066\n",
            "VALIDATION LOSS 2.426920199394226\n",
            "2.490543818473816\n",
            "2.461560344696045\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-1ce6d44072e0>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_segment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_segment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1292\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1293\u001b[0;31m         return F.cross_entropy(\n\u001b[0m\u001b[1;32m   1294\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m             \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3477\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3479\u001b[0;31m     return torch._C._nn.cross_entropy_loss(\n\u001b[0m\u001b[1;32m   3480\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3481\u001b[0m         \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = next(test_loader)\n",
        "seq, labels = test_data[:, :-1], test_data[:, 1:]\n",
        "test_loss = 0.\n",
        "model.eval()\n",
        "for seq_segment, labels_segment in zip(seq.chunk(segments, dim = -1), labels.chunk(segments, dim = -1)): # ten passes of (8, 512)\n",
        "    with torch.no_grad():\n",
        "        y_pred = model(seq_segment)\n",
        "        y_pred = y_pred.transpose(2,1)\n",
        "        loss = loss_fn(y_pred, labels_segment)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "print (\"TEST LOSS\", (test_loss / segments))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mu_kVu0dr9Tv",
        "outputId": "caf6fe6e-cd98-4c17-a851-966825911676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST LOSS 2.4852545738220213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sowEb9LOsEpX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}