{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdwvvRDjn6-e",
        "outputId": "52cd21c7-0578-47ae-ecb2-39c6f941cb51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: faiss-gpu in /usr/local/lib/python3.10/dist-packages (1.7.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import tqdm\n",
        "import gzip\n",
        "\n",
        "!pip3 install einops\n",
        "from einops import rearrange, repeat, pack, unpack, einsum\n",
        "from einops.layers.torch import Rearrange\n",
        "\n",
        "\n",
        "from functools import partial, wraps\n",
        "from contextlib import contextmanager, ExitStack\n",
        "from pathlib import Path\n",
        "from filelock import FileLock\n",
        "import pickle\n",
        "\n",
        "import transformers\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "!pip3 install faiss-gpu\n",
        "import faiss\n",
        "\n",
        "!pip3 install datasets\n",
        "import datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = 5\n",
        "sequence_pos = torch.arange(sequence_length, dtype=torch.long)\n",
        "context_pos = torch.arange(2*sequence_length, dtype=torch.long)\n",
        "#context_pos = torch.arange(-sequence_length, sequence_length, dtype=torch.long)\n",
        "sequence_rel_pos = rearrange(sequence_pos, 'i -> i 1')\n",
        "context_rel_pos = rearrange(context_pos, 'j -> 1 j')\n",
        "rel_pos = context_rel_pos - sequence_rel_pos\n",
        "rel_pos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6a7_oEmrW7H",
        "outputId": "8a0e1efe-3369-4aaa-d176-b8e8bddf49f6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
              "        [-1,  0,  1,  2,  3,  4,  5,  6,  7,  8],\n",
              "        [-2, -1,  0,  1,  2,  3,  4,  5,  6,  7],\n",
              "        [-3, -2, -1,  0,  1,  2,  3,  4,  5,  6],\n",
              "        [-4, -3, -2, -1,  0,  1,  2,  3,  4,  5]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Outline\n",
        "\n",
        "# # Embedding\n",
        "# token_ids = tokenizer(raw_text)\n",
        "# x = embedding(token_ids)\n",
        "\n",
        "# # BLOCK x n (layers)\n",
        "\n",
        "# # Attention\n",
        "# residual = x.copy()\n",
        "# x = layernorm(x)\n",
        "# x = attention(x) # XL, KNN_XL\n",
        "# x = x + residual\n",
        "\n",
        "# # Feedforward\n",
        "# residual = x.copy()\n",
        "# x = layernorm(x)\n",
        "# x = linear(x)\n",
        "# x = activation(x)\n",
        "# x = dropout(x)\n",
        "# x = linear_2(x)\n",
        "# x = x + residual\n",
        "\n",
        "\n",
        "# # Output\n",
        "# x = layernorm(x)\n",
        "# token_ids = embedding_reverse(x)\n",
        "# loss = cross_entropy(token_ids, labels)"
      ],
      "metadata": {
        "id": "8iNqEz3DskaY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MemorizingTransformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_dimension,\n",
        "        vocab_size,\n",
        "        heads = 8,\n",
        "        depth = 10,\n",
        "        dropout = 0,\n",
        "        head_dimension = 64,\n",
        "        max_knn_memories = 32000,\n",
        "        topk = 5,\n",
        "\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.heads = heads\n",
        "        self.embedding_dimension = embedding_dimension\n",
        "        self.dropout = dropout\n",
        "        self.depth = depth\n",
        "        self.head_dimension = head_dimension\n",
        "        self.max_knn_memories = max_knn_memories\n",
        "        self.topk = topk\n",
        "\n",
        "        self.rel_pos = RelativePosition(rp_scale = head_dimension** 0.5,\n",
        "                                        heads = self.heads)\n",
        "        self.rel_pos_knn = RelativePosition(rp_scale = head_dimension** 0.5,\n",
        "                                        heads = self.heads)\n",
        "        self.embedding_matrix = nn.Embedding(vocab_size, self.embedding_dimension)\n",
        "\n",
        "        self.knn = KNN(head_dimension * heads, self.max_knn_memories)\n",
        "\n",
        "        self.layers = nn.ModuleList([])\n",
        "\n",
        "        for i in range(self.depth):\n",
        "\n",
        "            if i == self.depth-2:\n",
        "                layer_knn = self.knn\n",
        "            else:\n",
        "                layer_knn = None\n",
        "\n",
        "            self.layers.append(Block(layer_knn))\n",
        "\n",
        "        self.to_logits = nn.Sequential(\n",
        "            nn.LayerNorm(self.embedding_dimension),\n",
        "            nn.Linear(self.embedding_dimension, vocab_size)\n",
        "        )\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        x,\n",
        "        relative_positions = None,\n",
        "        xl_memories = None,\n",
        "        labels = None,\n",
        "    ):\n",
        "\n",
        "        batch_size, sequence_length = x.shape[0], x.shape[1]\n",
        "\n",
        "        # Position values\n",
        "        rel_pos = self.rel_pos(sequence_length)\n",
        "        rel_pos_knn = self.rel_pos_knn(sequence_length)\n",
        "\n",
        "        if xl_memories is not None:\n",
        "            xl_memories = xl_memories\n",
        "        else:\n",
        "            xl_memories = (None,) * self.depth # if we're in first chunk of document\n",
        "\n",
        "        # Iterator\n",
        "        xl_memories_iter = iter(xl_memories)\n",
        "\n",
        "        # Store the XL memories for each pass\n",
        "        new_xl_memories = []\n",
        "\n",
        "        # Embeddings\n",
        "        x = self.embedding_matrix(x)\n",
        "\n",
        "        for ind, block in enumerate(self.layers):\n",
        "\n",
        "            if ind == self.depth-2:\n",
        "                layer_rel_pos = rel_pos_knn\n",
        "            else:\n",
        "                layer_rel_pos = rel_pos\n",
        "\n",
        "            x, xl_mem = block(x, next(xl_memories_iter), layer_rel_pos)\n",
        "\n",
        "            if xl_mem is not None:\n",
        "                new_xl_memories.append(xl_mem)\n",
        "\n",
        "        logits = self.to_logits(x)\n",
        "\n",
        "        loss = F.cross_entropy(rearrange(logits, 'b n c -> b c n'), labels)\n",
        "        if len(new_xl_memories) > 0:\n",
        "            return loss, new_xl_memories\n",
        "        return loss\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-BwAUJ1Rtpfj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Architecture"
      ],
      "metadata": {
        "id": "qkqQIIdH29h-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RelativePosition(nn.Module):\n",
        "  def __init__(\n",
        "      self,\n",
        "      rp_scale,\n",
        "      num_buckets = 32,\n",
        "      rp_max_distance = 128,\n",
        "      heads = 8\n",
        "  ):\n",
        "      super().__init__()\n",
        "      self.scale = rp_scale\n",
        "      self.num_buckets = num_buckets\n",
        "      self.rp_max_distance = rp_max_distance\n",
        "      self.relative_attention_embedding = nn.Embedding(num_buckets, heads)\n",
        "\n",
        "  def relative_position_bucket(self, relative_position_matrix):\n",
        "      n = -relative_position_matrix\n",
        "      n = torch.max(n, torch.zeros_like(n))\n",
        "\n",
        "      max_exact = self.num_buckets // 2\n",
        "\n",
        "      is_small = n < max_exact\n",
        "      val_if_large = max_exact + (torch.log(n.float() / max_exact) / math.log(self.rp_max_distance / max_exact) * (self.num_buckets - max_exact)).long()\n",
        "      val_if_large = torch.min(val_if_large, torch.full_like(val_if_large, self.num_buckets - 1))\n",
        "\n",
        "      return torch.where(is_small, n, val_if_large)\n",
        "\n",
        "  def forward(self, sequence_length):\n",
        "\n",
        "      sequence_pos = torch.arange(sequence_length, dtype=torch.long)\n",
        "      context_pos = torch.arange(2 * sequence_length, dtype=torch.long)\n",
        "      sequence_rel_pos = rearrange(sequence_pos, 'i -> i 1')\n",
        "      context_rel_pos = rearrange(context_pos, 'j -> 1 j')\n",
        "      rel_pos = context_rel_pos - sequence_rel_pos\n",
        "\n",
        "      position_bucket_indices = self.relative_position_bucket(rel_pos)\n",
        "\n",
        "      rp_values = self.relative_attention_embedding(position_bucket_indices)\n",
        "      rp_values = rearrange(rp_values, 'i j h -> () h i j')\n",
        "      return rp_values * self.scale\n",
        "\n",
        "\n",
        "\n",
        "class KNN():\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        max_memories,\n",
        "        ):\n",
        "        self.dim = dim\n",
        "        self.max_memories = max_memories\n",
        "        self.shape = (max_memories, 2, dim)\n",
        "        self.db_offset = 0\n",
        "        self.db_filepath = \"./memory.memmap\"\n",
        "        self.db = np.memmap(self.db_filepath, mode = 'w+', dtype = np.float32, shape = self.shape)\n",
        "        self.index = faiss.IndexFlatL2(dim)\n",
        "\n",
        "\n",
        "    def add_to_db(self, new_data):\n",
        "        new_data_len = new_data.shape[0]\n",
        "        ids = (np.arange(new_data_len) + self.db_offset)\n",
        "        self.db[ids] = new_data.detach().numpy()\n",
        "        self.db_offset += new_data_len\n",
        "        # Write to file\n",
        "        self.db.flush()\n",
        "\n",
        "\n",
        "    def search_and_retrieve(self, query_vecs, topk):\n",
        "        query_vecs = query_vecs\n",
        "        distances, indices = self.index.search(query_vecs, topk)\n",
        "        kvs = self.db[indices]\n",
        "        return kvs\n",
        "\n",
        "    def add(self, new_data):\n",
        "        # Input is b n 2 d, flatten to (b n) 2 d\n",
        "        new_data = new_data.flatten(0,1)\n",
        "        # Add to db\n",
        "        self.add_to_db(new_data)\n",
        "        # Only keys are used in knn index\n",
        "        keys, vals = new_data.unbind(dim=-2)\n",
        "        keys = keys.detach().numpy()\n",
        "        # Add (b n) d tensors to index\n",
        "        keys = np.ascontiguousarray(keys)\n",
        "        # Add to index\n",
        "        self.index.add(keys)\n",
        "\n",
        "    def search(self, query_vecs, topk):\n",
        "        # can override topk\n",
        "        query_batch_size, query_seq_len = query_vecs.shape[0], query_vecs.shape[1]\n",
        "        # Input is b n d, flatten to (b n) d\n",
        "        query_vecs = query_vecs.flatten(0,1)\n",
        "        kvs = self.search_and_retrieve(np.ascontiguousarray(query_vecs.detach().numpy()), topk)\n",
        "        # kvs are (b n) k 2 d, unflatten to b n k 2 d\n",
        "        kvs = torch.tensor(kvs)\n",
        "        kvs = torch.unflatten(kvs, 0, (query_batch_size, query_seq_len))\n",
        "        return kvs\n",
        "\n",
        "\n",
        "    def clear(self):\n",
        "        self.index.reset()\n",
        "        self.db[:] = 0\n",
        "        self.db_offset = 0\n",
        "\n",
        "\n",
        "class XLAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_dimension,\n",
        "        heads = 8,\n",
        "        head_dimension = 64,\n",
        "        dropout = 0.,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.heads = heads\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.scale = head_dimension ** -0.5\n",
        "\n",
        "        self.query_matrix = nn.Linear(embedding_dimension, self.heads * head_dimension)\n",
        "        self.key_matrix = nn.Linear(embedding_dimension, self.heads * head_dimension)\n",
        "        self.value_matrix = nn.Linear(embedding_dimension, self.heads * head_dimension)\n",
        "        self.output_matrix = nn.Linear(self.heads * head_dimension, embedding_dimension)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        x, # batch_size, sequence_length, embedding_dimension\n",
        "        relative_positions = None,\n",
        "        xl_memory = None\n",
        "    ):\n",
        "\n",
        "        queries = self.query_matrix(x)\n",
        "        keys = self.key_matrix(x)\n",
        "        values = self.value_matrix(x)\n",
        "\n",
        "        queries = queries * self.scale\n",
        "\n",
        "        if xl_memory is not None:\n",
        "            k_xl, v_xl = xl_memory.unbind(dim = -2) # assume stacked\n",
        "            keys = torch.cat((k_xl, keys), dim = -2) # prepend XL memory\n",
        "            values = torch.cat((v_xl, values), dim = -2) # prepend XL memory\n",
        "            xl_sequence_length = k_xl.shape[1]\n",
        "\n",
        "        queries = rearrange(queries, 'b t (h d) -> b h t d', h = self.heads)\n",
        "        keys    = rearrange(keys, 'b t (h d) -> b h t d', h = self.heads)\n",
        "        qk      = einsum(queries, keys, 'b h i d, b h j d -> b h i j')\n",
        "\n",
        "        i, j = qk.shape[-2:]\n",
        "        if relative_positions is not None:\n",
        "            qk = relative_positions[..., -i:, -j:] + qk\n",
        "\n",
        "        qk = qk * self.scale\n",
        "\n",
        "        mask = torch.ones((i,j), dtype = torch.bool).triu(j-i+1)\n",
        "        qk = qk.masked_fill(mask, float('-inf'))\n",
        "\n",
        "        qk = F.softmax(qk, dim=-1)\n",
        "        qk = self.dropout(qk)\n",
        "\n",
        "        values = rearrange(values, 'b t (h d) -> b h t d', h=self.heads)\n",
        "        qkv = qk@values\n",
        "        qkv = rearrange(qkv, 'b h t d -> b t (h d)')\n",
        "\n",
        "        out = self.output_matrix(qkv)\n",
        "\n",
        "        # new XL memories\n",
        "\n",
        "        keys = rearrange(keys, 'b h t d -> b t (h d)', h = self.heads)\n",
        "        values = rearrange(values, 'b h t d -> b t (h d)', h=self.heads)\n",
        "        kv_memories = torch.stack((keys, values), dim=-2) # (batch, sequence_len, 2, dimension)\n",
        "\n",
        "\n",
        "        if xl_memory is not None:\n",
        "            xl_memories, current_input = kv_memories[:, :-xl_sequence_length], kv_memories[:, -xl_sequence_length:]\n",
        "            kv_to_add_xl = current_input\n",
        "        else:\n",
        "            kv_to_add_xl = kv_memories\n",
        "\n",
        "        return out, kv_to_add_xl\n",
        "\n",
        "\n",
        "\n",
        "class KNNAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_dimension,\n",
        "        knn,\n",
        "        heads = 8,\n",
        "        head_dimension = 64,\n",
        "        topk_retrieved_memories = 3,\n",
        "        dropout = 0.\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.heads = heads\n",
        "        self.scale = head_dimension ** -0.5\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.query_matrix = nn.Linear(embedding_dimension, heads * head_dimension)\n",
        "        self.key_matrix = nn.Linear(embedding_dimension, heads * head_dimension)\n",
        "        self.value_matrix = nn.Linear(embedding_dimension, heads * head_dimension)\n",
        "        self.output_matrix = nn.Linear(heads * head_dimension, embedding_dimension)\n",
        "\n",
        "        self.gate_bias = nn.Parameter(torch.randn(self.heads, 1, 1))\n",
        "        self.topk_retrieved_memories = topk_retrieved_memories\n",
        "        self.knn = knn\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        x, # batch_size, sequence_length, embedding_dimension\n",
        "        relative_positions = None,\n",
        "        xl_memory = None\n",
        "    ):\n",
        "        batch_size, sequence_length = x.shape[:2]\n",
        "        queries = self.query_matrix(x)\n",
        "        keys = self.key_matrix(x)\n",
        "        values = self.value_matrix(x)\n",
        "\n",
        "        queries = F.normalize(queries, dim=-1)\n",
        "        keys = F.normalize(keys, dim=-1)\n",
        "\n",
        "        if xl_memory is not None:\n",
        "            k_xl, v_xl = xl_memory.unbind(dim = -2) # unstack\n",
        "            keys = torch.cat((k_xl, keys), dim = -2) # prepend XL memory\n",
        "            values = torch.cat((v_xl, values), dim = -2) # prepend XL memory\n",
        "            xl_sequence_length = k_xl.shape[1]\n",
        "\n",
        "        ### LOCAL ATTENTION\n",
        "\n",
        "        queries = rearrange(queries, 'b t (h d) -> b h t d', h = self.heads)\n",
        "        keys    = rearrange(keys, 'b t (h d) -> b h t d', h = self.heads)\n",
        "        qk      = einsum(queries, keys, 'b h i d, b h j d -> b h i j')\n",
        "\n",
        "        i, j = qk.shape[-2:]\n",
        "        if relative_positions is not None:\n",
        "            qk = relative_positions[..., -i:, -j:] + qk\n",
        "\n",
        "        qk = qk * self.scale\n",
        "\n",
        "        mask = torch.ones((i,j), dtype = torch.bool).triu(j-i+1)\n",
        "        qk = qk.masked_fill(mask, float('-inf'))\n",
        "\n",
        "        qk = F.softmax(qk, dim=-1)\n",
        "\n",
        "        qk = self.dropout(qk)\n",
        "\n",
        "        values = rearrange(values, 'b t (h d) -> b h t d', h=self.heads)\n",
        "        qkv = qk@values\n",
        "\n",
        "        ### KNN ATTENTION\n",
        "\n",
        "        # If there are knn memories (we're not on the first segment) then perform knn attention\n",
        "        if self.knn.index.ntotal > 0:\n",
        "            # Convert queries to search form\n",
        "            queries = rearrange(queries, 'b h t d -> b t (h d)')\n",
        "            mem_kv = self.knn.search(queries, topk = self.topk_retrieved_memories) # returns b t k 2 d\n",
        "            mem_k, mem_v = mem_kv.unbind(dim = -2)\n",
        "            mem_k = rearrange(mem_k, 'b t k (h d) -> b h t k d', h=self.heads)\n",
        "            mem_v = rearrange(mem_v, 'b t k (h d) -> b h t k d', h=self.heads)\n",
        "\n",
        "            # Convert queries to attention form\n",
        "            queries = rearrange(queries, 'b t (h d) -> b h t d', h = self.heads)\n",
        "            mem_qk = einsum(queries, mem_k, 'b h t d, b h t k d -> b h t k')\n",
        "            mem_qk = mem_qk * self.scale\n",
        "\n",
        "            mem_qk = F.softmax(mem_qk, dim=-1)\n",
        "            mem_qk = self.dropout(mem_qk)\n",
        "            mem_qkv = einsum(mem_qk, mem_v, 'b h t k, b h t k d -> b h t d')\n",
        "\n",
        "            # Combined attentions\n",
        "\n",
        "            combined_qkv = mem_qkv * self.gate_bias + qkv * (1 - self.gate_bias)\n",
        "            combined_qkv = rearrange(combined_qkv, 'b h t d -> b t (h d)')\n",
        "            out = self.output_matrix(combined_qkv)\n",
        "\n",
        "        else:\n",
        "            qkv = rearrange(qkv, 'b h t d -> b t (h d)')\n",
        "            out = self.output_matrix(qkv)\n",
        "\n",
        "        # New XL memories\n",
        "        keys = rearrange(keys, 'b h t d -> b t (h d)', h = self.heads)\n",
        "        values = rearrange(values, 'b h t d -> b t (h d)', h=self.heads)\n",
        "        kv_memories = torch.stack((keys, values), dim=-2) # (batch, sequence_len, 2, dimension)\n",
        "\n",
        "        if xl_memory is not None:\n",
        "            # if we're on a middle/end segment of a document (there are previous XL memories)\n",
        "            xl_memories, current_kv = kv_memories[:, :-xl_sequence_length], kv_memories[:, -xl_sequence_length:]\n",
        "        else:\n",
        "            # if we're at the first segment\n",
        "            current_kv = kv_memories\n",
        "\n",
        "        self.knn.add(current_kv)\n",
        "\n",
        "        return out, current_kv\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, embedding_dimension, attention_type, dropout=0.):\n",
        "        super().__init__()\n",
        "        self.attention = attention_type\n",
        "        self.dim = embedding_dimension\n",
        "\n",
        "        self.ff_block = nn.Sequential(\n",
        "            nn.LayerNorm(self.dim),\n",
        "            nn.Linear(self.dim, self.dim * 4),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(self.dim * 4, self.dim))\n",
        "\n",
        "    def forward(self, x, xl_memories, rel_pos):\n",
        "        residual = x\n",
        "        norm = nn.LayerNorm(self.dim)\n",
        "        attn_out = norm(x)\n",
        "        attn_out, new_xl_memories = self.attention(attn_out, relative_positions=rel_pos, xl_memory=xl_memories)\n",
        "        attn_out += residual\n",
        "\n",
        "        residual = attn_out\n",
        "        ff_out = self.ff_block(attn_out)\n",
        "        ff_out += residual\n",
        "        return ff_out, new_xl_memories\n",
        "\n",
        "\n",
        "class MemorizingTransformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_dimension,\n",
        "        vocab_size,\n",
        "        max_knn_memories = 81920,\n",
        "        heads = 8,\n",
        "        depth = 10,\n",
        "        dropout = 0,\n",
        "        head_dimension = 64,\n",
        "        topk = 5,\n",
        "\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.heads = heads\n",
        "        self.embedding_dimension = embedding_dimension\n",
        "        self.dropout = dropout\n",
        "        self.depth = depth\n",
        "        self.head_dimension = head_dimension\n",
        "        self.max_knn_memories = max_knn_memories\n",
        "        self.topk = topk\n",
        "\n",
        "        ###########\n",
        "        self.rel_pos = RelativePosition(rp_scale = head_dimension** 0.5,\n",
        "                                        heads = self.heads)\n",
        "        self.rel_pos_knn = RelativePosition(rp_scale = head_dimension** 0.5,\n",
        "                                        heads = self.heads)\n",
        "        self.embedding_matrix = nn.Embedding(vocab_size, self.embedding_dimension)\n",
        "\n",
        "        self.knn = KNN(head_dimension * heads, self.max_knn_memories)\n",
        "\n",
        "\n",
        "\n",
        "        self.layers = nn.ModuleList([])\n",
        "        for i in range(self.depth):\n",
        "\n",
        "            if i == self.depth-2:\n",
        "                attention_type = KNNAttention(self.embedding_dimension,\n",
        "                            self.knn,\n",
        "                            heads = self.heads,\n",
        "                            head_dimension = self.head_dimension,\n",
        "                            dropout = self.dropout)\n",
        "            else:\n",
        "                attention_type = XLAttention(self.embedding_dimension,\n",
        "                            heads = self.heads,\n",
        "                            head_dimension = self.head_dimension,\n",
        "                            dropout = self.dropout)\n",
        "\n",
        "            self.layers.append(Block(self.embedding_dimension, attention_type))\n",
        "\n",
        "        self.to_logits = nn.Sequential(\n",
        "            nn.LayerNorm(self.embedding_dimension),\n",
        "            nn.Linear(self.embedding_dimension, vocab_size)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        x,\n",
        "        relative_positions = None,\n",
        "        xl_memories = None,\n",
        "        labels = None,\n",
        "    ):\n",
        "\n",
        "        batch_size, sequence_length = x.shape[0], x.shape[1]\n",
        "\n",
        "        # Position values\n",
        "        rel_pos = self.rel_pos(sequence_length)\n",
        "        rel_pos_knn = self.rel_pos_knn(sequence_length)\n",
        "\n",
        "        # If no XL memories (start of a sequence) then None type for each layer.\n",
        "        # There is one set of XL memories for each layer\n",
        "        # xl_memories = default(xl_memories, (None,) * self.num_xl_memory_layers)\n",
        "        if xl_memories is not None:\n",
        "            xl_memories = xl_memories\n",
        "        else:\n",
        "            xl_memories = (None,) * self.depth\n",
        "\n",
        "        # Iterator\n",
        "        xl_memories_iter = iter(xl_memories)\n",
        "\n",
        "        # Embeddings\n",
        "        x = self.embedding_matrix(x)\n",
        "\n",
        "        # Store the XL memories for each pass\n",
        "        new_xl_memories = []\n",
        "\n",
        "        for ind, block in enumerate(self.layers):\n",
        "\n",
        "            if i == self.depth-2:\n",
        "                layer_rel_pos = rel_pos_knn\n",
        "            else:\n",
        "                layer_rel_pos = rel_pos\n",
        "\n",
        "            x, xl_mem = block(x, next(xl_memories_iter), layer_rel_pos)\n",
        "\n",
        "            if xl_mem is not None:\n",
        "                ############\n",
        "                new_xl_memories.append(xl_mem.detach())\n",
        "\n",
        "\n",
        "\n",
        "        logits = self.to_logits(x)\n",
        "\n",
        "        # Training\n",
        "        loss = F.cross_entropy(rearrange(logits, 'b n c -> b c n'), labels)\n",
        "        if len(new_xl_memories) > 0:\n",
        "            return loss, new_xl_memories\n",
        "        return loss"
      ],
      "metadata": {
        "id": "UiZYFXGH1DUc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Loop"
      ],
      "metadata": {
        "id": "AxhoZR1724ub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEGMENTS = 10\n",
        "SEQUENCE_LENGTH = 512\n",
        "CHUNK_SIZE = (SEGMENTS * SEQUENCE_LENGTH) + 1 #### we need +1 because we shift by 1 for each sequence\n",
        "BATCH_SIZE = 8\n",
        "LEARNING_RATE = 2e-4\n",
        "MAX_GRAD_CLIP_NORM = 0.5\n",
        "VALIDATE_EVERY = 100\n",
        "MAX_KNN_MEMORIES = BATCH_SIZE * 1 * SEQUENCE_LENGTH * SEGMENTS\n",
        "\n",
        "\n",
        "dataset = datasets.load_dataset(\"ccdv/arxiv-summarization\", split='train', streaming=True)\n",
        "raw_dataset = list(dataset.take(3500))\n",
        "\n",
        "raw_articles = [x['article'] for x in raw_dataset]\n",
        "raw_articles = [x for x in raw_articles if len(x) > CHUNK_SIZE]\n",
        "converted = [np.fromstring(doc, dtype=np.uint8) for doc in raw_articles]\n",
        "\n",
        "def clip_article(doc, chunk_size):\n",
        "    remainder = len(doc) % chunk_size\n",
        "    return doc[:-remainder]\n",
        "\n",
        "clipped = [clip_article(doc, CHUNK_SIZE) for doc in converted]\n",
        "\n",
        "\n",
        "chunked = np.array([doc.reshape(-1, CHUNK_SIZE) for doc in clipped])\n",
        "\n",
        "processed_data = torch.tensor(np.concatenate(chunked), dtype=torch.long)\n",
        "processed_data.shape\n",
        "eighty_split = int(processed_data.shape[0] * .8)\n",
        "ninety_split = int(processed_data.shape[0] * .9)\n",
        "train_loader = iter(DataLoader(processed_data[:eighty_split], batch_size = BATCH_SIZE, shuffle = True))\n",
        "val_loader = iter(DataLoader(processed_data[eighty_split:ninety_split], batch_size = BATCH_SIZE, shuffle = True))\n",
        "test_loader = iter(DataLoader(processed_data[ninety_split:], batch_size = BATCH_SIZE, shuffle = True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "PxEbU2e31FqM",
        "outputId": "04d7add0-ba06-469b-8055-184827e07211"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-bb46656f414f>:16: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
            "  converted = [np.fromstring(doc, dtype=np.uint8) for doc in raw_articles]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3401,) + inhomogeneous part.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-bb46656f414f>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mchunked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclipped\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mprocessed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3401,) + inhomogeneous part."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model = MemorizingTransformer(embedding_dimension = 128,\n",
        "                              vocab_size = 128,\n",
        "                              max_knn_memories = MAX_KNN_MEMORIES)\n",
        "\n",
        "optim = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
        "model.train()\n",
        "\n",
        "\n",
        "for i in tqdm.tqdm(range(200), mininterval = 10., desc = 'training'):\n",
        "\n",
        "    model.train()\n",
        "    train_loss = 0.\n",
        "\n",
        "    # Clear XL memories\n",
        "    xl_memories = None\n",
        "\n",
        "    # Clear KNN memory\n",
        "    model.knn.clear()\n",
        "\n",
        "    data = next(train_loader)\n",
        "    seq, labels = data[:, :-1], data[:, 1:]\n",
        "\n",
        "\n",
        "    # Each pass will be (BATCH_SIZE * SEGMENTS) iterations\n",
        "    for seq_segment, labels_segment in zip(seq.chunk(SEGMENTS, dim = -1), labels.chunk(SEGMENTS, dim = -1)):\n",
        "\n",
        "        loss, xl_memories = model(\n",
        "            seq_segment,\n",
        "            labels = labels_segment,\n",
        "            xl_memories = xl_memories\n",
        "        )\n",
        "\n",
        "        train_loss += loss.item() / SEGMENTS\n",
        "        (loss / SEGMENTS).backward()\n",
        "        print (\"segment complete\")\n",
        "\n",
        "\n",
        "    print(f'training loss: {train_loss}')\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_CLIP_NORM)\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "\n",
        "\n",
        "    if not (i % VALIDATE_EVERY):\n",
        "        model.eval()\n",
        "\n",
        "        valid_data = next(val_loader)\n",
        "        valid_loss = 0.\n",
        "\n",
        "        with torch.no_grad():\n",
        "            xl_memories = None\n",
        "            model.knn.clear()\n",
        "            seq, labels = data[:, :-1], data[:, 1:]\n",
        "\n",
        "            for seq_segment, labels_segment in zip(seq.chunk(SEGMENTS, dim = -1), labels.chunk(SEGMENTS, dim = -1)):\n",
        "\n",
        "                loss, xl_memories = model(\n",
        "                    seq_segment,\n",
        "                    labels = labels_segment,\n",
        "                    xl_memories = xl_memories\n",
        "                )\n",
        "\n",
        "                valid_loss += loss.item() / SEGMENTS\n",
        "\n",
        "        print(f'valid loss: {valid_loss}')"
      ],
      "metadata": {
        "id": "FMeWhG2p2Cko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n1KSke0O3NIq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}